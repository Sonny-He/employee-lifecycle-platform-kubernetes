name: 'Terraform Infrastructure - CS3'

on:
  workflow_dispatch: 
    inputs:
      action: 
        description: 'Terraform action to perform'
        required: true
        default: 'plan'
        type: choice
        options: 
          - plan
          - apply
          - destroy
      auto_approve:
        description: 'Auto-approve apply/destroy (skip confirmation)'
        required: false
        default: false
        type:  boolean
      deploy_k8s:
        description: 'Deploy Kubernetes resources after apply'
        required: false
        default: true
        type: boolean

permissions: 
  contents: read
  pull-requests: write
  id-token: write  # Required for AWS OIDC authentication

env: 
  TF_VERSION: '1.6.0'
  AWS_REGION: 'eu-central-1'
  EKS_CLUSTER_NAME:  'cs3-employee-platform'
  VPC_ID: 'vpc-072a8b181a467d24b'

jobs:
  terraform:
    name: 'Terraform ${{ github.event.inputs.action || ''plan'' }}'
    runs-on: ubuntu-latest
    environment:  production

    steps:
    - name: Checkout
      uses:  actions/checkout@v4

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::098347675427:role/GitHubActionsRole
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Test AWS Access
      run: |
        aws sts get-caller-identity
        echo "âœ… AWS authentication successful"

    - name:  Terraform Format Check
      id: fmt
      run: |
        cd terraform
        terraform fmt -check -recursive
      continue-on-error: true

    - name:  Terraform Init
      id: init
      run: |
        cd terraform
        terraform init

    - name: Terraform Validate
      id: validate
      run: |
        cd terraform
        terraform validate -no-color

    - name: Terraform Plan
      id: plan
      if:  github.event. inputs.action == 'plan' || github.event.inputs.action == 'apply'
      run: |
        cd terraform
        terraform plan -no-color -input=false -out=tfplan
      continue-on-error: true

    - name: Terraform Plan Status
      if: steps.plan. outcome == 'failure'
      run: |
        echo "âŒ Terraform plan failed. Review errors above."
        exit 1

    - name: Terraform Apply (Safety Check)
      if: github.event.inputs.action == 'apply' && github.event.inputs. auto_approve == 'false'
      run: |
        echo "âš ï¸ Manual approval required. Please review the plan above."
        echo "To apply, re-run this workflow with 'auto_approve' set to true."
        exit 1

    - name: Terraform Apply
      if: github.event.inputs.action == 'apply' && github. event.inputs.auto_approve == 'true'
      run:  |
        cd terraform
        terraform apply -auto-approve -input=false tfplan
      env: 
        TF_VAR_employee_db_password: ${{ secrets.EMPLOYEE_DB_PASSWORD }}

    - name: Terraform Destroy (Safety Check)
      if: github.event.inputs.action == 'destroy' && github. event.inputs.auto_approve == 'false'
      run: |
        echo "âš ï¸ DESTROY requires manual approval. This will delete ALL infrastructure!"
        echo "To destroy, re-run this workflow with 'auto_approve' set to true."
        exit 1

    - name: Terraform Destroy
      if: github.event. inputs.action == 'destroy' && github.event.inputs.auto_approve == 'true'
      run: |
        cd terraform
        terraform destroy -auto-approve -input=false
      env: 
        TF_VAR_employee_db_password: ${{ secrets.EMPLOYEE_DB_PASSWORD }}

    - name: Configure kubectl
      if: github.event.inputs.action == 'apply' && github. event.inputs.auto_approve == 'true' && github.event.inputs.deploy_k8s == 'true'
      run: |
        aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
        kubectl cluster-info
        kubectl get nodes

    - name: Deploy AWS Load Balancer Controller
      if: github.event.inputs.action == 'apply' && github. event.inputs.auto_approve == 'true' && github.event.inputs.deploy_k8s == 'true'
      run: |
        echo "Installing Helm..."
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        
        echo "Cleaning up old ALB controller if exists..."
        kubectl delete deployment aws-load-balancer-controller -n kube-system --ignore-not-found
        kubectl delete clusterrole aws-load-balancer-controller --ignore-not-found
        kubectl delete clusterrolebinding aws-load-balancer-controller --ignore-not-found
        
        echo "Installing ALB Controller CRDs..."
        kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds? ref=master"
        
        echo "Waiting for CRDs to be ready..."
        sleep 5
        
        echo "Installing AWS Load Balancer Controller via Helm..."
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
          --set serviceAccount. create=false \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set region=${{ env.AWS_REGION }} \
          --set vpcId=${{ env. VPC_ID }} \
          --wait \
          --timeout 5m
        
        echo "âœ… AWS Load Balancer Controller deployed successfully!"

    - name:  Deploy Employee Portal
      if: github.event.inputs.action == 'apply' && github.event. inputs.auto_approve == 'true' && github.event.inputs.deploy_k8s == 'true'
      run: |
        echo "Deploying Employee Portal..."
        kubectl apply -f kubernetes/employee-portal.yaml
        kubectl apply -f kubernetes/employee-portal-frontend.yaml
        
        echo "Waiting for deployments to be ready..."
        kubectl wait --for=condition=available --timeout=300s deployment/employee-portal -n employee-services || true
        
        echo "âœ… Employee Portal deployed successfully!"

    - name: Upload Plan Artifact
      if: github.event.inputs.action == 'plan'
      uses: actions/upload-artifact@v4
      with:
        name:  terraform-plan
        path: terraform/tfplan
        retention-days: 5

    - name:  Workflow Summary
      if: always()
      run: |
        echo "## ðŸš€ Terraform Workflow Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Action** | ${{ github.event.inputs.action || 'plan' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Auto-approve** | ${{ github.event.inputs.auto_approve || 'false' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Deploy K8s** | ${{ github.event.inputs.deploy_k8s || 'true' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Region** | ${{ env.AWS_REGION }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Cluster** | ${{ env.EKS_CLUSTER_NAME }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Triggered by** | @${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Workflow Run** | [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) |" >> $GITHUB_STEP_SUMMARY
